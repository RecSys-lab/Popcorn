# ------------------- General configurations -------------------
general:
  # Framework name
  name: "Popcorn"
  # Root path for the framework
  root_path: "" # Empty for local, "Popcorn" for using in Google Colab
  # Path to save the outputs of the framework (if empty, it will be saved in the root_path/outputs)
  output_path: ""
  # Verbose logging (prints detailed logs)
  verbose: true
# ------------------------- Datasets configurations ------------------------
datasets:
  # Textual
  unimodal:
    movielens:
      # Dataset name
      name: MovieLens
      # Version to be used
      version: "1m" # '100k' | '1m' | '25m'
      # Root path to download the dataset (if exists, it will not be downloaded again)
      download_path: "E:/Datasets/MovieLens"
    poison_rag_plus:
      # Dataset name
      name: Poison-RAG-Plus
      # LLM prefix for text processing
      llm: "llama" # 'openai' | 'st' | 'llama'
      # Use augmented textual path
      augmented: true # True to use augmented textual path
      # Maximum number of text parts
      max_parts: 15
  # Visual dataset (Popcorn)
  multimodal:
    popcorn:
      # Dataset name
      name: Popcorn-visual
      # Embedding sources to be used (in an array)
      embedding_sources: ["full_movies"] # 'full_movies' | 'movie_shots' | 'movie_trailers'
      # Aggregated embedding sources to be used (in an array)
      agg_embedding_sources: ["full_movies_agg"] # 'full_movies_agg' | 'movie_shots_agg' | 'movie_trailers_agg'
      # Feature extraction methods to be used (in an array)
      cnns: ["incp3"] # 'incp3' | 'vgg19'
    mmtf:
      # Dataset name
      name: MMTF-14K
      # Path to the dataset root directory
      download_path: "E:/Datasets/MMTF-14k"
      # Audio variant to use
      audio_variant: "blf" # 'blf' | 'ivec'
      # Audio BLF PCA variance to combine various features (between 0 and 1, e.g., 0.95 for 95%)
      audio_blf_pca: 0.95
      # Visual variant to use
      visual_variant: "cnn" # 'avf' | 'cnn'
# ------------------------- Pipelines configurations ------------------------
pipelines:
  # Movie trailers finder and downloader pipeline
  trailer_fetch:
    # Pipeline name
    name: Trailer-Fetcher
    # Path to the pipeline
    download_path: "E:/Datasets/Movies/MovieTrailers"
  # Movie frames extractor pipeline
  frame_extractor:
    # Pipeline name
    name: Frame-Extractor
    # A root directory containing the movie video files
    movies_path: "E:/Datasets/Movies/Videos"
    # A root directory to save the extracted frames
    frames_path: "E:/Datasets/Movies/MovieFrames"
    # Output file format
    frame_format: "jpg"
    # Frequency of frames extraction (picking 'n' frames every second, between 1 and 25)
    frequency: 1
    # Frame width (with automatic aspect ratio, should match the CNN model input size, between 1 and 1920)
    frame_width: 420
  # Movie frames visual embedding extractor pipeline
  visual_embedding_extractor:
    # Pipeline name
    name: Visual-Embedding-Extractor
    # A root directory containing the extracted movie frames
    frames_path: "E:/Datasets/Movies/MovieFrames"
    # A root directory to save the extracted visual embeddings
    features_path: "E:/Datasets/Movies/MovieFeatures"
    # CNN model to be used for feature extraction
    cnn: "incp3" # 'incp3' | 'vgg19'
    # Packets size (number of frames in each packet, between 1 and 50)
    packet_size: 25
  # Visual embedding aggregation pipeline
  visual_embedding_aggregator:
    # Pipeline name
    name: Visual-Embedding-Aggregator
    # A root directory containing the extracted movie visual embeddings
    features_path: "E:/Datasets/Movies/MovieFeatures"
    # A root directory to save the aggregated visual embeddings
    agg_features_path: "E:/Datasets/Movies/MovieAggFeatures"
    # Aggregation methods to be used (in an array)
    aggregation_methods: ["Max", "Mean"] # 'Max' | 'Mean'
  # Movie frames and extracted features shot detection pipeline
  shot_detector:
    # Pipeline name
    name: Shot-Detector
    # Output shots path
    shots_path: "E:/Datasets/Movies/MovieShots"
    # Shot boundaries detection threshold (between 0.1 to 1.0, default: 0.7)
    threshold: 0.8
    # Variants of shot detection
    variants:
      # Shot detection from frames
      from_frames:
        # A root directory containing the extracted movie frames
        frames_path: "E:/Datasets/Movies/MovieFrames"
        # Output file format
        frame_format: "jpg"
      # Shot detection from visual embeddings
      from_embeddings:
        # A root directory containing the extracted movie visual embeddings
        features_path: "E:/Datasets/Movies/MovieFeatures"
        # Packets size (number of frames in each packet, between 1 and 50)
        packet_size: 25
# ------------------------- Modality configurations ------------------------
modalities:
  # Path to the output directory
  output_path: "E:/Datasets/Fused-Embeddings"
  # The list of selected modalities to be used
  # [Supported]: 'audio_mmtf' | 'visual_mmtf' | 'text_rag_plus' | 'visual_popcorn'
  selected: ["audio_mmtf", "visual_mmtf", "text_rag_plus"]
  # Methods for modality fusion
  fusion_methods:
    # List of fusion methods to be used
    selected: ["concat", "cca", "pca"] # 'concat' | 'cca' | 'pca'
    # CCA components (only for 'cca' fusion method)
    cca_components: 40
    # CCA regularization (only for 'cca' fusion method)
    cca_reg: 0.0 # 0.0 to 1.0, such as 1e-2
    # PCA variance to retain (only for 'pca' fusion method, between 0 and 1, e.g., 0.95 for 95%)
    pca_variance: 0.95
    # PCA regularization (only for 'pca' fusion method)
    pca_reg: 0.0 # 0.0 to 1.0, such as 1e-2
# ------------------------- Experimental configurations ------------------------
setup:
  # Seed for reproducibility
  seed: 42
  # Number of cores for k-core filtering
  k_core: 10
  # Model choice for the experiment
  model_choice: "vbpr" # 'cf' | 'vbpr' | 'amr' | 'vmf'
  # Dataset split configuration
  split:
    # Mode of dataset splitting
    mode: "random" # 'random' | 'temporal' | 'per_user'
    # Ratio of test data
    test_ratio: 0.2
  # Is it a fast prototype run? Run only in one epoch with a small subset of data
  is_fast_prototype: true
  # Use GPU for training (if available)
  use_gpu: false
  # Use parallel processing (if available)
  use_parallel: true
  # Number of epochs for training
  n_epochs: 10
# ------------------------- Recommender configurations ------------------------
recommender:
  # Number of top-N recommendations
  top_n: 10 # 2 | 5 | 10 | 15 | 20 | 25 | 30 | 50
  # Minimum number of ratings to consider a user/item as warm
  cold_threshold: 5
